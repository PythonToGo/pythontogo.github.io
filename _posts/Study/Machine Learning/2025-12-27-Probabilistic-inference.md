---
title: "Probabilistic Inference : MLE, MAP, and Bayesian Estimation"
description: MLE, MAP, and Bayesian Estimation
date: 2025-12-27
categories: [Study, Machine Learning]
tags: [Machine Learning, Probabilistic Inference, MLE, MAP, Bayesian Estimation]
# pin: true
math: true
mermaid: true
comments: true
# image: 
#     path: 
#     lqip: 
#     alt: 
---

# Probabilistic Inference

## 1. Introduction & Model Assumptions

ëª©ì : ê´€ì°°í•œ ë°ì´í„° $$D$$ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª¨ë¸ íŒŒë¼ë¯¸í„° $$\theta$$ë¥¼ ì¶”ë¡ í•˜ê±°ë‚˜, ìƒˆë¡œìš´ ë°ì´í„° $$x_{new}$$ì˜ ë°œìƒ í™•ë¥ ì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì´ë‹¤.

### i.i.d. Assumptions

ë°ì´í„° ë¶„ì„ì„ ìœ„í•´ ê° ê´€ì°°ê°’ë“¤ì´ **independent and identically distributed** ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•œë‹¤. (í™•ë¥ ì´ë‹ˆê¹Œ)

- **Identical distribution**: ëª¨ë“  ë°ì´í„°ê°€ ë™ì¼í•œ íŒŒë¼ë¯¸í„° $$\theta$$ë¥¼ ê°€ì§„ë‹¤
- **Independence**: ê° ë°ì´í„° í¬ì¸íŠ¸ëŠ” ì„œë¡œ ì˜í–¥ì„ ì£¼ì§€ ì•Šìœ¼ë¯€ë¡œ ì „ì²´ í™•ë¥ ì„ ê°œë³„ í™•ë¥ ì˜ ê³±ìœ¼ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤:
  $$
  p(D \mid \theta) = \prod_{i=1}^N p(x_i \mid \theta)
  $$

---

## 2. Maximum Likelihood Estimation (MLE)

MLEëŠ” ê´€ì°°ëœ ë°ì´í„°ì˜ ë°œìƒ í™•ë¥ ì¸ **Likelihood** $$p(D \mid \theta)$$ë¥¼ ìµœëŒ€í™”í•˜ëŠ” íŒŒë¼ë¯¸í„° $$\theta$$ë¥¼ ì°¾ëŠ” ê¸°ë²•ì´ë‹¤.

### Objective

$$
\theta_{MLE} = \arg\max_{\theta} p(D \mid \theta)
$$

### Log-likelihood

ê³„ì‚°ì˜ í¸ì˜ì„±ê³¼ ìˆ˜ì¹˜ì  ì•ˆì •ì„±ì„ ìœ„í•´ Likelihood ëŒ€ì‹ , **Log-likelihood** $$\log p(D \mid \theta)$$ë¥¼ ìµœëŒ€í™”í•œë‹¤. Logarithmì€ Monotonic transformì´ë¯€ë¡œ ìµœëŒ“ê°’ì˜ ìœ„ì¹˜ë¥¼ ë³´ì¡´í•˜ê³ , ê³±ì…ˆì„ ë§ì…ˆìœ¼ë¡œ ë³€í™˜í•´ì„œ ë” ì‰¬ì›€.

### Coin Flip ì˜ˆì‹œ

ë™ì „ ë˜ì§€ê¸°ì—ì„œ Tì™€ Hì˜ ê°œìˆ˜ë¥¼ ê°ê° $$\lvert T \rvert$$, $$\lvert H\rvert$$ë¼ í•  ë•Œ:

$$
\theta_{MLE} = \frac{\left|T\right|}{\left|T\right|+\left|H\right|}
$$

### Gaussian ì˜ˆì‹œ

í‰ê·  $$\mu$$ë¥¼ ì¶”ì •í•  ë•Œ:

$$
\mu_{MLE} = \frac{1}{N} \sum_{i=1}^N x_i
$$

ì´ëŠ” ë°ì´í„°ì˜ ì‚°ìˆ  í‰ê· ê³¼ ê°™ë‹¤. 


> ğŸ’¡ **ì¶”ê°€ ì„¤ëª…**
> 
> MLEëŠ” ë°ì´í„°ê°€ ì ì„ ë•Œ ì§ê´€ê³¼ ì–´ê¸‹ë‚˜ëŠ” ê²°ê³¼ë¥¼ ë‚¼ ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ë™ì „ì„ ë‘ ë²ˆ ë˜ì ¸ ëª¨ë‘ Hê°€ ë‚˜ì˜¤ë©´, MLEëŠ” ë’·ë©´ì´ ë‚˜ì˜¬ í™•ë¥  $$\theta$$ë¥¼ 0ìœ¼ë¡œ ì¶”ì •í•˜ì§€ë§Œ, ì´ëŠ” ìš°ë¦¬ì˜ ì¼ë°˜ ìƒì‹ Prior beliefì™€ ë‹¤ë¥´ë‹¤. ê·¸ë˜ì„œ ì—¬ê¸°ì„œ (ì•„ë˜ì— ë‚˜ì˜¬) MAPëŠ” ë°ì´í„°ë¥¼ ê´€ì°°í•˜ê¸° ì „ì—, ìš°ë¦¬ê°€ ê°€ì§„ ì£¼ê´€ì  ë¯¿ìŒì¸ **Prior distribution** $$p(\theta)$$ë¥¼ ë¨¼ì € ìˆ˜í•™ì ìœ¼ë¡œ ê²°í•©í•œë‹¤. ê·¸ë¦¬ê³ , ë‹¨ìˆœíˆ ë°ì´í„°ì˜ ê°€ëŠ¥ì„± $$p(D \mid \theta)$$ì„ ë†’ì´ëŠ” ê²ƒë³´ë‹¤ëŠ”, **ë°ì´í„°ê°€ ì£¼ì–´ì¡Œì„ ë•Œ íŒŒë¼ë¯¸í„°ê°€ ì‹¤ì œë¡œ ì¡´ì¬í•  í™•ë¥ **ì¸ **Posterior distribution** $$p(\theta \mid D)$$ë¥¼ ê³ ë ¤í•œë‹¤. ì•„ë˜ ë‚˜ì˜¤ëŠ” MAPì˜ ëª©ì ì€ Posterior distributionì—ì„œ ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ê°’, ì¦‰ ìµœë¹ˆê°’(Mode)ì„ ì°¾ëŠ” ê²ƒì´ë‹¤. 


## Bayesian Inference

Bayesian ê´€ì ì—ì„œ íŒŒë¼ë¯¸í„° $$\theta$$ë¥¼ ê³ ì •ëœ ê°’ì´ ì•„ë‹Œ, í™•ë¥  ë¶„í¬ë¥¼ ê°€ì§„ í™•ë¥  ë³€ìˆ˜ë¡œ ì·¨ê¸‰í•œë‹¤.

### Prior Distribution $$p(\theta)$$

ë°ì´í„°ë¥¼ ê´€ì°°í•˜ê¸° ì „ì—, íŒŒë¼ë¯¸í„°ì— ëŒ€í•´ ê°€ì§€ê³  ìˆëŠ” ì£¼ê´€ì ì¸ ë¯¿ìŒì„ ì˜ë¯¸í•œë‹¤.

### Posterior Distribution $$p(\theta \mid D)$$

ë°ì´í„°ë¥¼ ê´€ì°°í•œ í›„ ì—…ë°ì´íŠ¸ëœ ë¯¿ìŒì´ë‹¤. Bayes' Ruleì— ì˜í•´ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ëœë‹¤:

$$
p(\theta \mid D) = \frac{p(D \mid \theta)p(\theta)}{p(D)}
$$

- **Likelihood** $$p(D \mid \theta)$$: ë°ì´í„°ê°€ ì£¼ì–´ì¡Œì„ ë•Œ íŒŒë¼ë¯¸í„°ì˜ ê°€ëŠ¥ì„±
- **Evidence** $$p(D)$$: Normalizing constantë¡œ, posterior distributionì˜ í•©ì´ 1ì´ ë˜ë„ë¡ í•œë‹¤

> âš ï¸ **ì¤‘ìš”**: ê´€ê³„ì‹: Posterior $$\propto$$ Likelihood $$\times$$ Prior



## Maximum a Posteriori (MAP) Estimation

MAPì€ Posterior distributionì„ ìµœëŒ€í™”í•˜ëŠ” íŒŒë¼ë¯¸í„° ê°’ì„ ì°¾ëŠ” ë°©ì‹ì´ë‹¤.

### Objective

$$
\theta_{MAP} = \arg\max_{\theta} p(\theta \mid D) = \arg\max_{\theta} [\log p(D \mid \theta) + \log p(\theta)]
$$

### Priorì˜ ì˜í–¥

ë°ì´í„°ê°€ ì ì„ ë•Œ Priorì˜ ì˜í–¥ì´ ê°•í•˜ê³ , MLEê°€ ê°€ì§€ëŠ” ë°ì´í„° ë¶€ì¡±ì— ë”°ë¥¸ í¸í–¥ ë¬¸ì œë¥¼ ì™„í™”í•´ì¤€ë‹¤. ë°ì´í„°ê°€ ë§ì•„ì§ˆìˆ˜ë¡ Priorì˜ ì˜í–¥ë ¥ì€ ì¤„ì–´ë“¤ê³ , MAPì€ MLEì— ìˆ˜ë ´í•˜ê²Œ ëœë‹¤. 

### Coin Flipì—ì„œ Beta Priorë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ

$$
\theta_{MAP} = \frac{|T| + a - 1}{|H| + |T| + a + b - 2}
$$

#### Beta Prior

Beta PriorëŠ” Bernoulli or Binomial distributionì„ ë”°ë¥´ëŠ” ë°ì´í„°ë¥¼ ë¶„ì„í•  ë•Œ ê°€ì¥ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” prior distributionì´ë‹¤.

**ìˆ˜í•™ì  ì •ì˜**:

$$
\text{Beta}(\theta | a, b) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \theta^{a-1}(1 - \theta)^{b-1}
$$

- ì—¬ê¸°ì„œ $$a, b > 0$$ëŠ” ë¶„í¬ì˜ í˜•íƒœë¥¼ ê²°ì •í•˜ëŠ” íŒŒë¼ë¯¸í„°ì´ë‹¤
- $$\Gamma(n)$$ì€ Gamma functionìœ¼ë¡œ, ìì—°ìˆ˜ $$n$$ì— ëŒ€í•´ $$(n-1)!$$ê³¼ ê°™ë‹¤

**Conjugate Prior**: Beta distributionì€ Bernoulli likelihoodì— ëŒ€í•´ conjugate priorì´ë‹¤.

- ì´ëŠ”, Priorê°€ Beta ë¶„í¬ì¼ ë•Œ, ë°ì´í„°ë¥¼ ë°˜ì˜í•œ í›„ì˜ Posteriorë„ ë°˜ë“œì‹œ Beta ë¶„í¬ê°€ ë¨ì„ ì˜ë¯¸í•œë‹¤
- ì´ ì„±ì§ˆì— ì˜í•´ ë³µì¡í•œ ì ë¶„ ê³„ì‚° ì—†ì´ ë‹¨ìˆœíˆ íŒŒë¼ë¯¸í„°ë¥¼ ë”í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œ posterior distributionì„ êµ¬í•  ìˆ˜ ìˆë‹¤

**Pseudo-counts í•´ì„**: $$a$$ì™€ $$b$$ëŠ” ê³¼ê±°ì— ê´€ì°°í•œ ë°ì´í„°ì˜ íšŸìˆ˜ë¡œ í•´ì„í•œë‹¤. ì½”ì¸ í”Œë¦½ì— ë‹¤ì‹œ ì ìš©í•˜ë©´:

- $$a$$: ê³¼ê±°ì— ê´€ì°°í•œ Tì˜ íšŸìˆ˜
- $$b$$: ê³¼ê±°ì— ê´€ì°°ëœ Hì˜ íšŸìˆ˜
- ë§Œì•½ $$a=1, b=1$$ì´ë¼ë©´, ì´ëŠ” Uniform distributionì´ ë˜ì–´ ì•„ë¬´ëŸ° ì •ë³´ê°€ ì—†ëŠ” ìƒíƒœì´ê³ , ì´ë•Œ MAPì€ MLEì™€ ë™ì¼í•œ ê²°ê³¼ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤


### Gaussian ì˜ˆì‹œ

ì •ê·œë¶„í¬ Prior $$N(\mu \mid 0, \alpha^{-1})$$ë¥¼ ê°€ì§ˆ ë•Œ:

$$
\mu_{MAP} = \frac{1}{N+\alpha} \sum_{i=1}^N x_i
$$

ì´ëŠ” $$\alpha > 0$$ì¼ ë•Œ, $$\mu_{MLE}$$ë³´ë‹¤ í•­ìƒ 0ì— ë” ê°€ê¹Œìš´ ê°’(**Shrinkage**)ì„ ê°€ì§„ë‹¤.



## Conjugate Priors

Priorì™€ Posteriorê°€ ë™ì¼í•œ Familyì˜ ë¶„í¬ë¥¼ ë”°ë¥¼ ë•Œ, í•´ë‹¹ Priorë¥¼ **Conjugate Prior**ë¼ê³  í•œë‹¤. ì´ ì„±ì§ˆì„ í†µí•´ Posterior distributionì˜ í˜•íƒœë¥¼ ì ë¶„ ì—†ì´ pattern matchingì„ í†µí•´ ì‰½ê²Œ ë„ì¶œ ê°€ëŠ¥í•˜ë‹¤.

### ì£¼ìš” ì¡°í•©

- Bernoulli Likelihood & Beta Prior â†’ Beta Posterior
- Binomial Likelihood & Beta Prior â†’ Beta Posterior
- Poisson Likelihood & Gamma Prior â†’ Gamma Posterior

### Posterior mean

**Posterior mean**ì€ ëŒ€ì²´ë¡œ Prior meanê³¼ MLE estimate ì‚¬ì´ì˜ Compromise(ì ˆì¶©ì•ˆ)ìœ¼ë¡œ ë‚˜íƒ€ë‚¸ë‹¤.



## Posterior Predictive Distribution

ìƒˆë¡œìš´ ë°ì´í„° $$x_{new}$$ë¥¼ ì˜ˆì¸¡í•  ë•Œ, ë‹¨ìˆœíˆ í•˜ë‚˜ì˜ ì  ì¶”ì •ì¹˜(MLE, MAP)ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, Posterior distribution ì „ì²´ë¥¼ ê³ ë ¤í•˜ëŠ” ë°©ì‹ì´ë‹¤.

### Definition

$$
p(x_{new} \mid D, a, b) = \int p(x_{new} \mid \theta) p(\theta \mid D, a, b) d\theta
$$

### Marginalization

íŒŒë¼ë¯¸í„° $$\theta$$ì— ëŒ€í•´ ì ë¶„í•´ì„œ $$\theta$$ë¥¼ ì œê±°í•˜ê³  ë°ì´í„°ì— ëŒ€í•œ ì§ì ‘ì ì¸ í™•ë¥ ì„ êµ¬í•˜ëŠ” ê³¼ì •ì´ë‹¤.

### Fully Bayesian Analysis

ì´ ë°©ì‹ì€ íŒŒë¼ë¯¸í„°ì— ëŒ€í•œ ë¶ˆí™•ì‹¤ì„±ì„ ëª¨ë‘ ê³ ë ¤í•˜ê¸° ë•Œë¬¸ì— ì  ì¶”ì • ë°©ì‹(MLE, MAP)ë³´ë‹¤ ë” í¬ê´„ì ì¸ ë¶„ì„ì´ ê°€ëŠ¥í•˜ë‹¤.


## ê²°ë¡ 

| êµ¬ë¶„ | Maximum Likelihood (MLE) | Maximum a Posteriori (MAP) | Fully Bayesian |
|------|-------------------------|---------------------------|----------------|
| ëª©í‘œ | $$\max p(D \mid \theta)$$ | $$\max p(\theta \mid D)$$ | $$p(\theta \mid D)$$ ì „ì²´ ì¶”ì • |
| ê²°ê³¼ | Point estimate | Point estimate | Full distribution |
| Prior ì‚¬ìš© | ì—†ìŒ (Uniformê³¼ ìœ ì‚¬) | ì‚¬ìš© | ì‚¬ìš© |

Probabilistic InferenceëŠ” ë°ì´í„°(Likelihood)ë¼ëŠ” ìƒˆë¡œìš´ ì¦ê±°ì™€ ê¸°ì¡´ì˜ ì§€ì‹(Prior) ì‚¬ì´ì—ì„œ ê· í˜•ì„ ë§ì¶° ë‚˜ê°€ëŠ” ê³¼ì •ê³¼ ê°™ë‹¤. ë°ì´í„°ê°€ ìŒ“ì¼ìˆ˜ë¡ ìš°ë¦¬ì˜ ë¯¿ìŒ(Posterior)ì€ ë” ìƒ¤í”„í•´ì§€ê³ (peaky), ì¦‰ ë‹¤ì‹œ ë§í•´ ë” í™•ì‹ ì— ì°¬ ì˜ˆì¸¡ì„ í•  ìˆ˜ ìˆë‹¤.
 